{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "284f6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RAKESH MOURYA\\\\Desktop\\\\Bike_Sharing_Prediction\\\\Bike_Sharing_Prediction'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/RAKESH MOURYA/Desktop/Bike_Sharing_Prediction/Bike_Sharing_Prediction\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d92a99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class datapreprocessing:\n",
    "    root_dir: Path\n",
    "    n_features_to_select: int\n",
    "    data_path: Path\n",
    "    transformed_train_path: Path\n",
    "    transformed_test_path: Path\n",
    "    preprocessor_obj_path: Path\n",
    "    test_size: float = 0.3\n",
    "    random_state: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44eb83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bike_rental.constants import*\n",
    "from bike_rental.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a570b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        \n",
    "    def get_data_preprocessing(self) ->datapreprocessing:\n",
    "        \n",
    "        config=self.config.data_preprocessing\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_preprocessing_config =datapreprocessing(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            n_features_to_select=self.params.n_features_to_select,\n",
    "            data_path=Path(config.data_path),\n",
    "            transformed_train_path=Path(config.transformed_train_path),\n",
    "            transformed_test_path=Path(config.transformed_test_path),\n",
    "            preprocessor_obj_path=Path(config.preprocessor_obj_path)      \n",
    "        )\n",
    "        \n",
    "        return data_preprocessing_config\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af1e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from bike_rental import logger\n",
    "from bike_rental.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6985c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7265e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bike_rental import logger\n",
    "import pickle\n",
    "class data_preprocessing:\n",
    "    def __init__(self,config: datapreprocessing):\n",
    "        self.config=config\n",
    "    \n",
    "    def transform_data(self):\n",
    "        logger.info(\"Reading dataset for preprocessing...\")\n",
    "        df = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        # --- your mapping + dummy code ---\n",
    "        df['season'] = df.season.map({1:'spring',2:'summer',3:'fall',4:'winter'})\n",
    "        df['mnth'] = df.mnth.map({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'June',\n",
    "                                  7:'July',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\n",
    "        df['weathersit'] = df.weathersit.map({1:'Clear',2:'Mist + Cloudy',3:'Light Snow',4:'Snow + Fog'})\n",
    "        df['weekday'] = df.weekday.map({0:'Sun',1:'Mon',2:'Tue',3:'Wed',4:'Thu',5:'Fri',6:'Sat'})\n",
    "\n",
    "        df = df.drop(['atemp','instant','dteday','casual','registered'], axis=1)\n",
    "\n",
    "        month = pd.get_dummies(df.mnth, drop_first=True)\n",
    "        weekday = pd.get_dummies(df.weekday, drop_first=True)\n",
    "        weathersit = pd.get_dummies(df.weathersit, drop_first=True)\n",
    "        season = pd.get_dummies(df.season, drop_first=True)\n",
    "\n",
    "        df = pd.concat([df, month, weekday, weathersit, season], axis=1)\n",
    "        df.drop(['season','mnth','weekday','weathersit'], axis=1, inplace=True)\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler_var = ['hum', 'windspeed', 'temp', 'cnt']\n",
    "        df[scaler_var] = scaler.fit_transform(df[scaler_var])\n",
    "        \n",
    "        # --- Split ---\n",
    "        train, test = train_test_split(df, test_size=0.3, random_state=100)\n",
    "        train.to_csv(self.config.transformed_train_path, index=False)\n",
    "        test.to_csv(self.config.transformed_test_path, index=False)\n",
    "\n",
    "        # --- Save preprocessor object (optional placeholder now) ---\n",
    "        with open(self.config.preprocessor_obj_path, \"wb\") as f:\n",
    "            pickle.dump({\"mapping\": \"done\"}, f)\n",
    "\n",
    "        logger.info(f\"Preprocessing complete. Train & test saved at {self.config.root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c89ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-13 16:05:09,110: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-09-13 16:05:09,118: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-09-13 16:05:09,126: INFO: common: created directory at: artifacts]\n",
      "[2025-09-13 16:05:09,134: INFO: common: created directory at: artifacts/data_preprocessing]\n",
      "[2025-09-13 16:05:09,134: INFO: 1727429553: Reading dataset for preprocessing...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-13 16:05:09,310: INFO: 1727429553: Preprocessing complete. Train & test saved at artifacts\\data_preprocessing]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_preprocessing_config = config.get_data_preprocessing()\n",
    "    data_transforming = data_preprocessing(config=data_preprocessing_config)\n",
    "    data_transforming.transform_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
